{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 3 Assignment - ML Bootcamp",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEslPzD4HNPG"
      },
      "source": [
        "ML Bootcamp 2021 - Week 3: Assignment\n",
        "\n",
        "- In this week you will learn more about the Pandas and specifically use it to create features\n",
        "- Finally these features will be used to train a Logistic Regression model and you will submit your solution to the Kaggle ****Titanic Machine Learning from Disaster**** competition\n",
        "- The comments will have most of the instructions\n",
        "- Attempt the questions using only python/pandas as much as possible as it is a very in-demand skill right now and learning it will be beneficial\n",
        "\n",
        "## USE TRAIN DATASET FROM THE TITANIC DATASET PROVIDED ONLY UNLESS SPECIFIED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyU4EAcwHTAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c3d296-8334-4d4f-ceaf-a923a648f6a5"
      },
      "source": [
        "# Import the necessary Libraries here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "!pip install category_encoders\n",
        "\n",
        "import category_encoders as ce"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 21.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 19.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 16.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAuyyEi1HmR_"
      },
      "source": [
        "## Q1. What is the average ticket price per ticket class(Pclass) for each individual port of embarkation? In other words, what is the price of each ticket class for each category of \"Embarked\" column?\n",
        "\n",
        "## Your answer should be in the following format as a Python Dictionary\n",
        "\n",
        "{<br>\n",
        "  (Pclass,Embarked Category) : Avg Fare<br>\n",
        "}\n",
        "\n",
        "Eg:\n",
        "\n",
        "{<br>\n",
        " (1, 'C'): Avg Fare,<br>\n",
        " (1, 'Q'): Avg Fare,<br>\n",
        " (1, 'S'): Avg Fare,<br>\n",
        " .<br>\n",
        " .<br>\n",
        " .<br>\n",
        " so on..<br>\n",
        "}\n",
        "\n",
        "\n",
        "## You can verify your answer as follows: \n",
        " - For the \"Embarked\" category 'Q' and 'Pclass' of 1 the average ticket price is \\$ 90\n",
        " - For the \"Embarked\" category 'S' and 'Pclass' of 3 the average ticket price is \\$ 14.64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRZOmi3iDGoc"
      },
      "source": [
        "df = pd.read_csv(\"./train.csv\")\n",
        "\n",
        "# arr = df['Embarked'].value_counts().index.tolist()\n",
        "\n",
        "# print(arr)\n",
        "\n",
        "\n",
        "\n",
        "# embCount = []\n",
        "# pClass = []\n",
        "\n",
        "# dicts = {}\n",
        "\n",
        "# for idx, i in enumerate(arr):\n",
        "#   embCount.append(df['Embarked'] == i)\n",
        "#   pClass.append(df['Pclass'] == idx + 1)\n",
        "#   print(idx + 1)\n",
        "\n",
        "\n",
        "# for idx, pCl in enumerate(arr):\n",
        "#     for idx2, eCl in enumerate(arr):\n",
        "#         dicts[idx + 1, arr[idx2]] = round(df[embCount[idx2]][pClass[idx]]['Fare'].mean(), 2) \n",
        "\n",
        "# {\n",
        "#     (1, 'S'): 70.36, \n",
        "#     (1, 'C'): 104.72, \n",
        "#     (1, 'Q'): 90.0, \n",
        "#     (2, 'S'): 20.33, \n",
        "#     (2, 'C'): 25.36, \n",
        "#     (2, 'Q'): 12.35, \n",
        "#     (3, 'S'): 14.64, \n",
        "#     (3, 'C'): 11.21, \n",
        "#     (3, 'Q'): 11.18\n",
        "# }\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oph5WCmrKKFj"
      },
      "source": [
        "## Q2. Create the \"Title\" feature in your dataset as an additional column and call it \"Title\". This \"Title\" will be extracted from the name and will be the Title given to each name which can be \"Mr.\", \"Mrs.\", \"Dr.\" and many more. Refer to the last question of Week 1 Assignment for reference\n",
        "\n",
        "- Only create the extra column called \"Title\" in your existing dataframe, no need to report any answer as you will be using all these features in the next few questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8WMMM6uIh7y"
      },
      "source": [
        "# Try to use regular expressions and use the pandas .apply() lambda function to solve \n",
        "# this as these are very powerful functions that will benefit you if learned now\n",
        "df['Titles'] = df['Name'].apply(lambda x:re.findall('[A-Za-z]+\\.', x)[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9Eufd9xKpI9"
      },
      "source": [
        "## Q3. Use the dataframe from above, which should include the \"Title\" column now, if you have successfully completed Q2. Encode this \"Title\" column using any encoding technique of your choice. Explore the various encoding techniques by reading this article:\n",
        "\n",
        "https://www.kdnuggets.com/2021/05/deal-with-categorical-data-machine-learning.html\n",
        "\n",
        "\n",
        "- As a start you can use any of the following techniques but there are many more\n",
        "  - pandas get_dummies()\n",
        "  - One hot encoding\n",
        "  - Label encoding\n",
        "- Explore each of the above techniques as you will learn a lot just by reading them\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr4u8hOYDEBT",
        "outputId": "19c0ca3a-536d-41a8-e396-4e89b53bf814"
      },
      "source": [
        "pd.get_dummies(df['Titles']).value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Capt.  Col.  Countess.  Don.  Dr.  Jonkheer.  Lady.  Major.  Master.  Miss.  Mlle.  Mme.  Mr.  Mrs.  Ms.  Rev.  Sir.\n",
              "0      0     0          0     0    0          0      0       0        0      0      0     1    0     0    0     0       517\n",
              "                                                                      1      0      0     0    0     0    0     0       182\n",
              "                                                                      0      0      0     0    1     0    0     0       125\n",
              "                                                             1        0      0      0     0    0     0    0     0        40\n",
              "                              1    0          0      0       0        0      0      0     0    0     0    0     0         7\n",
              "                              0    0          0      0       0        0      0      0     0    0     0    1     0         6\n",
              "                                                     1       0        0      0      0     0    0     0    0     0         2\n",
              "       1     0          0     0    0          0      0       0        0      0      0     0    0     0    0     0         2\n",
              "       0     0          0     0    0          0      0       0        0      1      0     0    0     0    0     0         2\n",
              "                                                                             0      1     0    0     0    0     0         1\n",
              "                                                                                    0     0    0     1    0     0         1\n",
              "1      0     0          0     0    0          0      0       0        0      0      0     0    0     0    0     0         1\n",
              "0      0     0          0     0    0          1      0       0        0      0      0     0    0     0    0     0         1\n",
              "                                   1          0      0       0        0      0      0     0    0     0    0     0         1\n",
              "                        1     0    0          0      0       0        0      0      0     0    0     0    0     0         1\n",
              "             1          0     0    0          0      0       0        0      0      0     0    0     0    0     0         1\n",
              "             0          0     0    0          0      0       0        0      0      0     0    0     0    0     1         1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ2f7IRsLsGe"
      },
      "source": [
        "## Q4. This is an open ended Optional question. Explore the data as we have done for Week 3 class and create a new feature of your own. Add it as a new column to the dataframe. \n",
        "\n",
        "- This feature might help you get a good score for your Kaggle submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWATjfkyLPEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7759b8e-965a-48fd-c7d6-bee510818bf6"
      },
      "source": [
        "# Follow the same process as the previous class notebooks on creating new columns. \n",
        "# This feature can be as simple as combining two columns by multiplying/dividing them with each other\n",
        "# Feel free to have a discussion in the group as this is a tricky Feature Engineering problem and might not be straightforward, hence optional.\n",
        "\n",
        "df['Fam_Size'] = df['SibSp'] + df['Parch'] + 1\n",
        "family_map = {1: 'Sin', 2: 'Min', 3: 'Min', 4: 'Med', 5: 'Med', 6: 'Med', 7: 'Big', 8: 'Big', 11: 'Big'}\n",
        "df['Group_size'] = df['Fam_Size'].map(family_map)\n",
        "df['Married'] = df['Titles'].apply(lambda x: 1 if x == \"Mrs.\" else 0)\n",
        "\n",
        "print(df.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived  Pclass  ... Fam_Size Group_size  Married\n",
            "0            1         0       3  ...        2        Min        0\n",
            "1            2         1       1  ...        2        Min        1\n",
            "2            3         1       3  ...        1        Sin        0\n",
            "3            4         1       1  ...        2        Min        1\n",
            "4            5         0       3  ...        1        Sin        0\n",
            "\n",
            "[5 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsNSVEJ5NDOW",
        "outputId": "5bbc0897-3f50-4a49-c980-1933c134ff7e"
      },
      "source": [
        "df['Fam_Size'] = df['SibSp'] + df['Parch'] + 1\n",
        "\n",
        "\n",
        "family_map = {1: 'Sin', 2: 'Min', 3: 'Min', 4: 'Med', 5: 'Med', 6: 'Med', 7: 'Big', 8: 'Big', 11: 'Big'}\n",
        "df['Group_size'] = df['Fam_Size'].map(family_map)\n",
        "\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived  Pclass  ... Fam_Size Group_size  Married\n",
            "0            1         0       3  ...        2        Min        0\n",
            "1            2         1       1  ...        2        Min        1\n",
            "2            3         1       3  ...        1        Sin        0\n",
            "3            4         1       1  ...        2        Min        1\n",
            "4            5         0       3  ...        1        Sin        0\n",
            "\n",
            "[5 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "2sDYbT_nQQIa",
        "outputId": "cdb4d1f0-fb90-482c-e986-08904af83b94"
      },
      "source": [
        "ce_OHE = ce.OneHotEncoder(cols=['Group_size'])\n",
        "\n",
        "df = ce_OHE.fit_transform(df)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Titles</th>\n",
              "      <th>Fam_Size</th>\n",
              "      <th>Group_size_1</th>\n",
              "      <th>Group_size_2</th>\n",
              "      <th>Group_size_3</th>\n",
              "      <th>Group_size_4</th>\n",
              "      <th>Married</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>Mrs.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>Miss.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>Mrs.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ... Group_size_3 Group_size_4  Married\n",
              "0            1         0       3  ...            0            0        0\n",
              "1            2         1       1  ...            0            0        1\n",
              "2            3         1       3  ...            0            0        0\n",
              "3            4         1       1  ...            0            0        1\n",
              "4            5         0       3  ...            0            0        0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAT438zOMD3-"
      },
      "source": [
        "## Q5. Create a LogisticRegression model as done in class. Use the dataset you have developed after answering all the previous questions(make sure all the data is only numerical). Train your model on the \"train.csv\" file, and then make predictions on your \"test.csv\" file. Format your output EXACTLY as shown in class at the very end and EXACTLY like the \"gender_submission.csv\" file provided as part of the challenge\n",
        "\n",
        "- Once you have created your own submission file, submit it on Kaggle for evaluation\n",
        "- Report the score as obtained from the kaggle website here and store it in a variable called ```result```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQEzAarlMyzK"
      },
      "source": [
        "#data normalization\n",
        "df.fillna(method=\"backfill\",inplace=True)\n",
        "df[['female','male']] = pd.get_dummies(df['Sex'])\n",
        "df['Age_Normalized'] = MinMaxScaler().fit_transform(np.array(df['Age']).reshape(-1, 1))\n",
        "df['Fare_Normalized'] = MinMaxScaler().fit_transform(np.array(df['Fare']).reshape(-1, 1))\n",
        "df['Fare_Normalized'] = MinMaxScaler().fit_transform(np.array(df['Fare']).reshape(-1, 1))\n",
        "df['Pclass_Normalized'] = MinMaxScaler().fit_transform(np.array(df['Pclass']).reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T75Xl8g4aEGT"
      },
      "source": [
        "df_train = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "DFI8_5znagND",
        "outputId": "fe167ac2-a454-4f46-deef-64f973adcacf"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Titles</th>\n",
              "      <th>Fam_Size</th>\n",
              "      <th>Group_size_1</th>\n",
              "      <th>Group_size_2</th>\n",
              "      <th>Group_size_3</th>\n",
              "      <th>Group_size_4</th>\n",
              "      <th>Married</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "      <th>Age_Normalized</th>\n",
              "      <th>Fare_Normalized</th>\n",
              "      <th>Pclass_Normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>C85</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>Mrs.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>0.139136</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>Miss.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>Mrs.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.103644</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.015713</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  ...  Fare_Normalized Pclass_Normalized\n",
              "0            1         0  ...         0.014151               1.0\n",
              "1            2         1  ...         0.139136               0.0\n",
              "2            3         1  ...         0.015469               1.0\n",
              "3            4         1  ...         0.103644               0.0\n",
              "4            5         0  ...         0.015713               1.0\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9uG6k_lT4As"
      },
      "source": [
        "drop_feat = ['PassengerId', 'Titles', 'Sex', 'Cabin', 'Embarked', 'Name', 'Fam_Size', 'Fare', 'SibSp', 'Parch', 'Age', 'Ticket', 'Pclass']\n",
        "df_train.drop(drop_feat, axis=1, inplace=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "TP24o8lqU5Tz",
        "outputId": "f41ae3a8-4929-41d0-860b-28591506a5a2"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Group_size_1</th>\n",
              "      <th>Group_size_2</th>\n",
              "      <th>Group_size_3</th>\n",
              "      <th>Group_size_4</th>\n",
              "      <th>Married</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "      <th>Age_Normalized</th>\n",
              "      <th>Fare_Normalized</th>\n",
              "      <th>Pclass_Normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>0.139136</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.103644</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.015713</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Group_size_1  ...  Fare_Normalized  Pclass_Normalized\n",
              "0         0             1  ...         0.014151                1.0\n",
              "1         1             1  ...         0.139136                0.0\n",
              "2         1             0  ...         0.015469                1.0\n",
              "3         1             1  ...         0.103644                0.0\n",
              "4         0             0  ...         0.015713                1.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR_DfwnNT2ts",
        "outputId": "e345394d-fdb6-4915-ae38-2089ec93372d"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.loc[:, 'Group_size_1':] , df.Survived)\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_predict = model.predict(x_test)\n",
        "print(classification_report(y_test, y_predict))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85       146\n",
            "           1       0.76      0.61      0.68        77\n",
            "\n",
            "    accuracy                           0.80       223\n",
            "   macro avg       0.79      0.75      0.76       223\n",
            "weighted avg       0.79      0.80      0.79       223\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "JHV5sZ9YZDnc",
        "outputId": "a0f34d20-f365-4320-e8ea-18c21aec960f"
      },
      "source": [
        "df_test = pd.read_csv(\"./test.csv\")\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  ... Cabin Embarked\n",
              "0          892       3  ...   NaN        Q\n",
              "1          893       3  ...   NaN        S\n",
              "2          894       2  ...   NaN        Q\n",
              "3          895       3  ...   NaN        S\n",
              "4          896       3  ...   NaN        S\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHV3VpmWCFAX",
        "outputId": "36d8a05c-7ebb-41b9-8223-7dae60c28794"
      },
      "source": [
        "df_test['Fam_Size'] = df_test['SibSp'] + df_test['Parch'] + 1\n",
        "family_map = {1: 'Sin', 2: 'Min', 3: 'Min', 4: 'Med', 5: 'Med', 6: 'Med', 7: 'Big', 8: 'Big', 11: 'Big'}\n",
        "df_test['Group_size'] = df_test['Fam_Size'].map(family_map)\n",
        "\n",
        "df_test['Titles'] = df_test['Name'].apply(lambda x:re.findall('[A-Za-z]+\\.', x)[0])\n",
        "df_test['Married'] = df_test['Titles'].apply(lambda x: 1 if x == \"Mrs.\" else 0)\n",
        "\n",
        "ce_OHE = ce.OneHotEncoder(cols=['Group_size'])\n",
        "\n",
        "df_test = ce_OHE.fit_transform(df_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRIWvOy-Zt2L"
      },
      "source": [
        "df_test.fillna(method=\"ffill\",inplace=True)\n",
        "df_test[['female','male']] = pd.get_dummies(df_test['Sex'])\n",
        "df_test['Age_Normalized'] = MinMaxScaler().fit_transform(np.array(df_test['Age']).reshape(-1, 1))\n",
        "df_test['Fare_Normalized'] = MinMaxScaler().fit_transform(np.array(df_test['Fare']).reshape(-1, 1))\n",
        "df_test['Fare_Normalized'] = MinMaxScaler().fit_transform(np.array(df_test['Fare']).reshape(-1, 1))\n",
        "df_test['Pclass_Normalized'] = MinMaxScaler().fit_transform(np.array(df_test['Pclass']).reshape(-1, 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxz36IuiVSia"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTi7-qVdVH-6"
      },
      "source": [
        "drop_feat = ['Titles', 'Sex', 'Cabin', 'Embarked', 'Name', 'Fam_Size', 'Fare', 'SibSp', 'Parch', 'Age', 'Ticket', 'Pclass']\n",
        "df_test.drop(drop_feat, axis=1, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJhP7sB-Vtma",
        "outputId": "4ffeb350-7d10-4fc1-9c9e-bb786ff7f832"
      },
      "source": [
        "list(df_test.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PassengerId',\n",
              " 'Group_size_1',\n",
              " 'Group_size_2',\n",
              " 'Group_size_3',\n",
              " 'Group_size_4',\n",
              " 'Married',\n",
              " 'female',\n",
              " 'male',\n",
              " 'Age_Normalized',\n",
              " 'Fare_Normalized',\n",
              " 'Pclass_Normalized']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqd_LeDKW_Yq",
        "outputId": "9173a65a-9fb5-40ec-9544-8b6480f052aa"
      },
      "source": [
        "list(df_train.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Survived',\n",
              " 'Group_size_1',\n",
              " 'Group_size_2',\n",
              " 'Group_size_3',\n",
              " 'Group_size_4',\n",
              " 'Married',\n",
              " 'female',\n",
              " 'male',\n",
              " 'Age_Normalized',\n",
              " 'Fare_Normalized',\n",
              " 'Pclass_Normalized']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIFLXz0LZR-b"
      },
      "source": [
        "submission_prediction = model.predict(df_test.loc[:, 'Group_size_1':])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSTfsS3aYGSa"
      },
      "source": [
        "df_submission = df_test[['PassengerId']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWaqaa7_YmF1"
      },
      "source": [
        "df_submission['Survived'] = submission_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByebwB9UUplR"
      },
      "source": [
        "df_submission.to_csv(\"submission_v1.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}